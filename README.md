# üöÄ Notre super mod√®le d'iA (oui, avec un petit 'i' pour l'humilit√©... ou pas) üöÄ

Salut √† toi, explorateur du code, curieux de l'IA (ou juste l√† pour le caf√©) ! Bienvenue dans le saint des saints de la pr√©diction, l√† o√π les bits dansent et les neurones... bah, ils calculent. On a concoct√© un truc pas piqu√© des hannetons, alors attache ta ceinture !

---

#### üõ†Ô∏è Installation : Pr√™t √† d√©coller ? üõ†Ô∏è

Pour que notre fus√©e de l'IA ne se transforme pas en vulgaire caillou, il faut un minimum de pr√©paration.

###### Le `.venv` (alias, notre petite bulle de s√©r√©nit√©)

Pour √©viter que ce projet ne mette le bazar dans ton PC (et vice-versa), on utilise un environnement virtuel. C'est comme une petite bulle magique o√π toutes les d√©pendances du projet vivent en harmonie, loin des conflits ext√©rieurs.

Si tu as Python (et un peu de chance) :

```bash
python -m venv .venv
```

Puis active-le (c'est le moment "abra cadabra") :

* **Windows (PowerShell) :**
    ```bash
    .\.venv\Scripts\Activate.ps1
    ```
* **Windows (CMD) :**
    ```bash
    .\.venv\Scripts\activate.bat
    ```
* **macOS / Linux :**
    ```bash
    source .venv/bin/activate
    ```
F√©licitations ! Tu es dans notre bulle. Ne respire pas trop fort, l'air y est pr√©cieux.

###### Le `requirements.txt` (alias, la liste de courses pour les geeks)

Maintenant que tu es dans la bulle, il faut la meubler avec les outils n√©cessaires. Ce fichier contient tout ce qu'il faut pour que Python comprenne nos blagues (et nos calculs).

Assure-toi que ton `.venv` est activ√©, puis :

```bash
pip install -r requirements.txt
```

√áa va mouliner un peu. C'est normal. C'est la magie qui s'op√®re.

---

#### üß† Le Mod√®le : Notre cerveau artificiel (enfin, un bout) üß†

Oublie les super-ordinateurs qui prennent toute une pi√®ce. Notre bijou, c'est un **super Neural Network (NN)** ! Oui oui, un NN √† l'√©tat de l'art (pour nous, en tout cas). Il est si avanc√© qu'il a :

* **2 couches "dense"** : parce que "dense", c'est le futur. Plus c'est dense, mieux c'est, n'est-ce pas ? üòâ
* **1 couche de pr√©diction** : c'est l√† que la magie se produit. Elle crache la r√©ponse, et on esp√®re qu'elle a raison.

Pr√©pare-toi √† √™tre √©merveill√© (ou juste √† voir des chiffres, c'est selon).

---

#### üó∫Ô∏è Architecture : O√π va quoi dans notre petit monde ? üó∫Ô∏è

Pour ne pas se perdre dans les m√©andres de notre g√©nie, voici comment on a organis√© notre projet. C'est un peu comme une carte au tr√©sor, mais le tr√©sor, c'est le code !

```
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ df_new.csv
‚îÇ   ‚îî‚îÄ‚îÄ df_old.csv
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ model_2024_08.pkl
‚îÇ   ‚îî‚îÄ‚îÄ preprocessor.pkl
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py
‚îÇ   ‚îî‚îÄ‚îÄ print_draw.py
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ requirements.txt
```

###### `data/` (Le garde-manger du projet)
Ici, c'est l√† que nos pr√©cieuses donn√©es vivent.
* `df_new.csv` : Les donn√©es fra√Æches du jour, pr√™tes √† √™tre d√©vor√©es par notre IA.
* `df_old.csv` : Les classiques, les v√©t√©rans, ceux qui ont tout vu. On les garde par nostalgie (et pour la r√©trospective).

###### `models/` (Le garage √† cerveaux)
Ce dossier, c'est notre caverne d'Ali Baba des cerveaux artificiels.
* `models.py` : Les plans de nos futurs cyborgs... euh, de nos mod√®les. C'est ici que l'on d√©finit l'architecture de nos NN et autres merveilles.
* `model_2024_08.pkl` : Une version sauvegard√©e de notre mod√®le. On l'a encapsul√© pour qu'il ne s'√©chappe pas et ne domine pas le monde... pas encore.
* `preprocessor.pkl` : L'outil magique qui pr√©pare les donn√©es avant de les donner √† manger au mod√®le. Sans lui, c'est l'indigestion assur√©e !

###### `modules/` (La bo√Æte √† outils de MacGyver)
Ce sont nos couteaux suisses du code. Chaque fichier est un expert dans son domaine.
* `evaluate.py` : Le juge impitoyable qui dit si notre mod√®le est un g√©nie ou un cancre.
* `preprocess.py` : Le chef cuisinier des donn√©es. Il les nettoie, les coupe, les assaisonne pour qu'elles soient parfaites pour notre IA.
* `print_draw.py` : L'artiste du groupe. Il transforme nos chiffres barbares en beaux graphiques pour que m√™me ta grand-m√®re puisse comprendre (enfin, presque).

---

On esp√®re que cette petite vir√©e dans notre projet t'a plu. N'h√©site pas √† jeter un ≈ìil au `main.py` pour lancer le grand spectacle !

*Fait avec amour, code et une bonne dose de caf√©ine (et un peu de folie).*


# TD => GOGOGO
## setup

- ### G√©n√©ration requirements.txt √† chaque installation de module
```bash
pip freeze > requirements.txt
```

- ### Installations des requis loguru: 
```bash
pip install loguru
```

- ### Installations des requis FastAPI/Streamlit: 
```bash
pip install nltk fastapi streamlit uvicorn requests pydantic
```
- #### Pour lancer le serveur MLflow :
```bash
uvicorn mlFlow_experiment:app --host 127.0.0.1 --port 9000 --reload
```
- #### Description des routes de l'API FastAPI :
[GET /docs](http://127.0.0.1:9000/docs#/)


- ### Installation des biblioth√®ques pour les tests unitaires: 
```bash
pip install pytest httpx
pytest test_predict_api.py
```

- ### Installations des requis pour MLflow : 
  > **mlFlow**
  MlFlow est un outil de gestion des exp√©riences de machine learning. Il permet de suivre les exp√©riences, de g√©rer les mod√®les et de visualiser les r√©sultats.
  

```bash
pip install mlflow scikit-learn pandas matplotlib
```

# Pour lancer le serveur MLflow :
```bash
mlflow ui
```

Cr√©ation d'un script pour g√©n√©rer 3 entrainements et les stocker sur MLflow : 
Les models cr√©√© sont stock√©s dans le dossier `models/` et pictures du drawloss sont stock√©s dans le dossier `figures/`.


```code

# Question pour follow-up :

- C'est quoi la meilleur valeur ? 
- 5 entrainnements ce n'est pas assez ? 
- influence du random ?

- Quel interet de r√©entrainer si on a d√©ja entrain√© un mod√®le jusqu'√† sa meilleur valeur?

- X = df.drop(columns=["nom", "prenom", "montant_pret"])
=> "est ce qu'on retire nom premon parce que √ßa n'a pas de sens statistique ou pour √©thique et rgpd ?"



# Entrainements RESULTS
## Entrainement sur les **anciennes donn√©es** :
==================Performance for run 0/5===================
MSE: 35648332.4621, MAE: 4868.7535, R¬≤: 0.7571
============================================================
==================Performance for run 1/5===================
MSE: 21110141.2394, MAE: 3514.9460, R¬≤: 0.8562
============================================================
==================Performance for run 2/5=================== => *Best OLD*
MSE: 21087705.3786, MAE: 3499.9798, R¬≤: 0.8563
============================================================
==================Performance for run 3/5===================
MSE: 21079447.9325, MAE: 3500.0007, R¬≤: 0.8564
============================================================
==================Performance for run 4/5===================
MSE: 21088151.5108, MAE: 3503.9029, R¬≤: 0.8563
============================================================

***

## Train de 5 avec les nouvelles donn√©es : 
==================Performance for run 0/5===================
MSE: 17590206.6978, MAE: 2934.2774, R¬≤: 0.8375
============================================================
==================Performance for run 1/5===================
MSE: 13534161.0819, MAE: 2393.7978, R¬≤: 0.8750
============================================================
==================Performance for run 2/5=================== => *Best NEW*
MSE: 13484831.7345, MAE: 2363.3283, R¬≤: 0.8754
============================================================
==================Performance for run 3/5===================
MSE: 13548757.8251, MAE: 2348.1724, R¬≤: 0.8748
============================================================
==================Performance for run 4/5===================
MSE: 13529502.2254, MAE: 2339.3840, R¬≤: 0.8750
============================================================

***

## 3 entrainement depuis le meilleur mod√®le de la passe old (60ca87cde38a42dab673c4c6491ba076) avec les donn√©es new pour voir si on a un meilleur r√©sultat :
==================Performance for run 0/3===================
MSE: 13519659.5319, MAE: 2393.4214, R¬≤: 0.8751
============================================================
==================Performance for run 1/3===================
MSE: 13564161.1756, MAE: 2389.5547, R¬≤: 0.8747
============================================================
==================Performance for run 2/3===================
MSE: 13500678.8155, MAE: 2363.6760, R¬≤: 0.8753
============================================================


```
> Arriv√© au bout de la 3√®me it√©ration, on a un mod√®le qui semble stable et performant sur les nouvelles donn√©es. 
> **Pas d'am√©lioration notable** de r√©entrainer sur les ancienne donn√©es





