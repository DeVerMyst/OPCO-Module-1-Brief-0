# üöÄ Notre super mod√®le d'iA (oui, avec un petit 'i' pour l'humilit√©... ou pas) üöÄ

Salut √† toi, explorateur du code, curieux de l'IA (ou juste l√† pour le caf√©) ! Bienvenue dans le saint des saints de la pr√©diction, l√† o√π les bits dansent et les neurones... bah, ils calculent. On a concoct√© un truc pas piqu√© des hannetons, alors attache ta ceinture !

---

#### üõ†Ô∏è Installation : Pr√™t √† d√©coller ? üõ†Ô∏è

Pour que notre fus√©e de l'IA ne se transforme pas en vulgaire caillou, il faut un minimum de pr√©paration.

###### Le `.venv` (alias, notre petite bulle de s√©r√©nit√©)

Pour √©viter que ce projet ne mette le bazar dans ton PC (et vice-versa), on utilise un environnement virtuel. C'est comme une petite bulle magique o√π toutes les d√©pendances du projet vivent en harmonie, loin des conflits ext√©rieurs.

Si tu as Python (et un peu de chance) :

```bash
python -m venv .venv
```

Puis active-le (c'est le moment "abra cadabra") :

* **Windows (PowerShell) :**
    ```bash
    .\.venv\Scripts\Activate.ps1
    ```
* **Windows (CMD) :**
    ```bash
    .\.venv\Scripts\activate.bat
    ```
* **macOS / Linux :**
    ```bash
    source .venv/bin/activate
    ```
F√©licitations ! Tu es dans notre bulle. Ne respire pas trop fort, l'air y est pr√©cieux.

###### Le `requirements.txt` (alias, la liste de courses pour les geeks)

Maintenant que tu es dans la bulle, il faut la meubler avec les outils n√©cessaires. Ce fichier contient tout ce qu'il faut pour que Python comprenne nos blagues (et nos calculs).

Assure-toi que ton `.venv` est activ√©, puis :

```bash
pip install -r requirements.txt
```

√áa va mouliner un peu. C'est normal. C'est la magie qui s'op√®re.

---

#### üß† Le Mod√®le : Notre cerveau artificiel (enfin, un bout) üß†

Oublie les super-ordinateurs qui prennent toute une pi√®ce. Notre bijou, c'est un **super Neural Network (NN)** ! Oui oui, un NN √† l'√©tat de l'art (pour nous, en tout cas). Il est si avanc√© qu'il a :

* **2 couches "dense"** : parce que "dense", c'est le futur. Plus c'est dense, mieux c'est, n'est-ce pas ? üòâ
* **1 couche de pr√©diction** : c'est l√† que la magie se produit. Elle crache la r√©ponse, et on esp√®re qu'elle a raison.

Pr√©pare-toi √† √™tre √©merveill√© (ou juste √† voir des chiffres, c'est selon).

---

#### üó∫Ô∏è Architecture : O√π va quoi dans notre petit monde ? üó∫Ô∏è

Pour ne pas se perdre dans les m√©andres de notre g√©nie, voici comment on a organis√© notre projet. C'est un peu comme une carte au tr√©sor, mais le tr√©sor, c'est le code !

```
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ df_new.csv
‚îÇ   ‚îî‚îÄ‚îÄ df_old.csv
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ model_2024_08.pkl
‚îÇ   ‚îî‚îÄ‚îÄ preprocessor.pkl
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py
‚îÇ   ‚îî‚îÄ‚îÄ print_draw.py
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ requirements.txt
```

###### `data/` (Le garde-manger du projet)
Ici, c'est l√† que nos pr√©cieuses donn√©es vivent.
* `df_new.csv` : Les donn√©es fra√Æches du jour, pr√™tes √† √™tre d√©vor√©es par notre IA.
* `df_old.csv` : Les classiques, les v√©t√©rans, ceux qui ont tout vu. On les garde par nostalgie (et pour la r√©trospective).

###### `models/` (Le garage √† cerveaux)
Ce dossier, c'est notre caverne d'Ali Baba des cerveaux artificiels.
* `models.py` : Les plans de nos futurs cyborgs... euh, de nos mod√®les. C'est ici que l'on d√©finit l'architecture de nos NN et autres merveilles.
* `model_2024_08.pkl` : Une version sauvegard√©e de notre mod√®le. On l'a encapsul√© pour qu'il ne s'√©chappe pas et ne domine pas le monde... pas encore.
* `preprocessor.pkl` : L'outil magique qui pr√©pare les donn√©es avant de les donner √† manger au mod√®le. Sans lui, c'est l'indigestion assur√©e !

###### `modules/` (La bo√Æte √† outils de MacGyver)
Ce sont nos couteaux suisses du code. Chaque fichier est un expert dans son domaine.
* `evaluate.py` : Le juge impitoyable qui dit si notre mod√®le est un g√©nie ou un cancre.
* `preprocess.py` : Le chef cuisinier des donn√©es. Il les nettoie, les coupe, les assaisonne pour qu'elles soient parfaites pour notre IA.
* `print_draw.py` : L'artiste du groupe. Il transforme nos chiffres barbares en beaux graphiques pour que m√™me ta grand-m√®re puisse comprendre (enfin, presque).

---

On esp√®re que cette petite vir√©e dans notre projet t'a plu. N'h√©site pas √† jeter un ≈ìil au `main.py` pour lancer le grand spectacle !

*Fait avec amour, code et une bonne dose de caf√©ine (et un peu de folie).*


# G√©n√©ration requirements.txt √† chaque installation de module
```bash
pip freeze > requirements.txt
```

# Installations des requis loguru: 
```bash
pip install loguru
```

# Installations des requis FastAPI/Streamlit: 
```bash
pip install nltk fastapi streamlit uvicorn requests pydantic
```
## Pour lancer le serveur MLflow :
```bash
uvicorn mlFlow_experiment:app --host 127.0.0.1 --port 9000 --reload
```
### Description des routes de l'API FastAPI :
[GET /docs](http://127.0.0.1:9000/docs#/)



# Installation des biblioth√®ques pour les tests unitaires: 
```bash
pip install pytest httpx
pytest test_predict_api.py
```

# Installations des requis pour MLflow : 
```bash
pip install mlflow scikit-learn pandas matplotlib
```

# Pour lancer le serveur MLflow :
```bash
mlflow ui
```

Cr√©ation d'un script pour g√©n√©rer 3 entrainements et les stocker sur MLflow : 
Les models cr√©√© sont stock√©s dans le dossier `models/` et pictures du drawloss sont stock√©s dans le dossier `figures/`.

```python



# mlFlow test repro: 
## 1er essai :
mae
4036.682826764578
mse
26815043.702234305
r2
0.8172922647660517
## 2eme essai :
mae
4036.682826764578
mse
26815043.702234305
r2
0.8172922647660517

** Arriv√© au bout de la 3√®me it√©ration, on a un mod√®le qui semble stable et performant sur les nouvelles donn√©es. **
=> revenir sur la version 1/3 (eme run de cette passe de 3 entrainnement pour valider le model qui est le + optimis√©)
==================Performance for run 1/3===================
MSE: 13484279.8583, MAE: 2341.7107, R¬≤: 0.8754
============================================================

==================Performance for run 2/3===================
MSE: 13509056.0376, MAE: 2336.8635, R¬≤: 0.8752
============================================================


- Quel interet de r√©entrainer si on a d√©ja entrain√© un mod√®le jusqu'√† sa meilleur valeur?

- Next step : Entrainer le mod√®le sur nouvelles donn√©es 5x puisque c'est le max puis sur les anciennes donn√©es ?